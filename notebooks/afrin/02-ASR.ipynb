{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8, 0.2],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.9, 0.1],\n",
       "        [0.1, 0.9]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from hidden import dynamics, infer\n",
    "# This is only if you want to use non-default optimization routines (global)\n",
    "from hidden.optimize.base import OptClass\n",
    "\n",
    "# Initializedynamics\n",
    "hmm = dynamics.HMM(2, 2)\n",
    "#hmm=dynamics.HMM(3,3) \n",
    "hmm.init_uniform_cycle(0.2, 0.1) \n",
    "#(0.2,0.1,0.05)\n",
    "hmm.A, hmm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.run_dynamics(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1\n",
       "0   1\n",
       "1   1\n",
       "2   1\n",
       "3   0\n",
       "4   1\n",
       ".. ..\n",
       "94  1\n",
       "95  0\n",
       "96  0\n",
       "97  0\n",
       "98  0\n",
       "\n",
       "[99 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obs_ts=pd.read_csv(\"C:/Users/arumana/OneDrive - Viewpoint Capital Corporation/Documents/sample_1_2d.csv\")\n",
    "obs_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize infer object\n",
    "analyzer = infer.MarkovInfer(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use initial 'guesses' for A and B to pass into the optimizer\n",
    "A_init = np.array([\n",
    "    [0.75, 0.3],\n",
    "    [0.25, 0.7]\n",
    "])\n",
    "\n",
    "B_init = np.array([\n",
    "    [0.95, 0.10],\n",
    "    [0.05, 0.90]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to run the optimization, we can call like this (these are all using\n",
    "# default arguments, so you dont actually need to include the symmetric or\n",
    "# opt_type arguments here)\n",
    "result_local = analyzer.optimize(obs_ts.to_numpy().reshape(-1), A_init, B_init, symmetric=False, opt_type=OptClass.Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_ts.to_numpy().reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a global optimization (using SHGO algorithm)\n",
    "result_global = analyzer.optimize(obs_ts.to_numpy().reshape(-1), A_init, B_init, symmetric=False, opt_type=OptClass.Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mCannot unify array(float64, 1d, C) and array(float64, 2d, C) for 'fwd_est.2', defined at c:\\code\\hmm\\hmm\\hidden\\filters\\bayesian.py (63)\n\u001b[1m\nFile \"..\\..\\hidden\\filters\\bayesian.py\", line 63:\u001b[0m\n\u001b[1mdef forward_algo(\n    <source elided>\n\n\u001b[1m    for i, obs in enumerate(observations):\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of assignment at c:\\code\\hmm\\hmm\\hidden\\filters\\bayesian.py (63)\u001b[0m\n\u001b[1m\nFile \"..\\..\\hidden\\filters\\bayesian.py\", line 63:\u001b[0m\n\u001b[1mdef forward_algo(\n    <source elided>\n\n\u001b[1m    for i, obs in enumerate(observations):\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m A_init_sym \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[0;32m      3\u001b[0m     [\u001b[39m0.75\u001b[39m, \u001b[39m0.25\u001b[39m],\n\u001b[0;32m      4\u001b[0m     [\u001b[39m0.25\u001b[39m, \u001b[39m0.75\u001b[39m]\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m B_init_sym \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[0;32m      8\u001b[0m     [\u001b[39m0.90\u001b[39m, \u001b[39m0.10\u001b[39m],\n\u001b[0;32m      9\u001b[0m     [\u001b[39m0.10\u001b[39m, \u001b[39m0.90\u001b[39m]\n\u001b[0;32m     10\u001b[0m ])\n\u001b[1;32m---> 12\u001b[0m result_local_sym \u001b[39m=\u001b[39m analyzer\u001b[39m.\u001b[39;49moptimize(obs_ts, A_init_sym, B_init_sym, symmetric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\code\\hmm\\hmm\\hidden\\infer.py:112\u001b[0m, in \u001b[0;36mMarkovInfer.optimize\u001b[1;34m(self, observations, trans_init, obs_init, symmetric, opt_type, algo_opts)\u001b[0m\n\u001b[0;32m    109\u001b[0m     dim_tuple \u001b[39m=\u001b[39m (trans_init\u001b[39m.\u001b[39mshape, obs_init\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39moptimize(observations, dim_tuple, symmetric\u001b[39m=\u001b[39msymmetric)\n\u001b[1;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49moptimize(observations, trans_init, obs_init, symmetric)\n",
      "File \u001b[1;32mc:\\code\\hmm\\hmm\\hidden\\optimize\\optimization.py:58\u001b[0m, in \u001b[0;36mLocalLikelihoodOptimizer.optimize\u001b[1;34m(self, obs_ts, A_guess, B_guess, symmetric)\u001b[0m\n\u001b[0;32m     55\u001b[0m bnds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_optimization_bounds(\u001b[39mlen\u001b[39m(param_init))\n\u001b[0;32m     57\u001b[0m \u001b[39m# run optimizer\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m=\u001b[39m so\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m     59\u001b[0m     fun\u001b[39m=\u001b[39;49mLikelihoodOptimizer\u001b[39m.\u001b[39;49mcalc_likelihood,\n\u001b[0;32m     60\u001b[0m     x0\u001b[39m=\u001b[39;49mparam_init,\n\u001b[0;32m     61\u001b[0m     args\u001b[39m=\u001b[39;49mopt_args,\n\u001b[0;32m     62\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgo,\n\u001b[0;32m     63\u001b[0m     bounds\u001b[39m=\u001b[39;49mbnds\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[39m# Return results\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m symmetric:\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:305\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m         iprint \u001b[39m=\u001b[39m disp\n\u001b[1;32m--> 305\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[39m=\u001b[39;49mjac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    306\u001b[0m                               bounds\u001b[39m=\u001b[39;49mnew_bounds,\n\u001b[0;32m    307\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step)\n\u001b[0;32m    309\u001b[0m func_and_grad \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mfun_and_grad\n\u001b[0;32m    311\u001b[0m fortran_int \u001b[39m=\u001b[39m _lbfgsb\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mintvar\u001b[39m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_optimize.py:332\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    328\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[0;32m    330\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    333\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[0;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    160\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m callable(grad):\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\code\\hmm\\hmm\\hidden\\optimize\\base.py:304\u001b[0m, in \u001b[0;36mLikelihoodOptimizer.calc_likelihood\u001b[1;34m(param_arr, dim, obs_ts, symmetric)\u001b[0m\n\u001b[0;32m    302\u001b[0m     A, B \u001b[39m=\u001b[39m LikelihoodOptimizer\u001b[39m.\u001b[39m_extract_parameters(param_arr, A_dim, B_dim)\n\u001b[0;32m    303\u001b[0m \u001b[39m# Generate predictions vector\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m _, pred \u001b[39m=\u001b[39m bayesian\u001b[39m.\u001b[39;49mforward_algo(obs_ts, A, B)\n\u001b[0;32m    305\u001b[0m \u001b[39m# Return likelihood value\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39mreturn\u001b[39;00m LikelihoodOptimizer\u001b[39m.\u001b[39m_likelihood(pred, np\u001b[39m.\u001b[39marray(obs_ts), B)\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\numba\\core\\dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    464\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mrstrip()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThis error may have been caused \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby the following argument(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00margs_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m         e\u001b[39m.\u001b[39mpatch_message(msg)\n\u001b[1;32m--> 468\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39;49m\u001b[39mtyping\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[39m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39m\u001b[39munsupported_error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arumana\\Anaconda3\\envs\\hid\\lib\\site-packages\\numba\\core\\dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mCannot unify array(float64, 1d, C) and array(float64, 2d, C) for 'fwd_est.2', defined at c:\\code\\hmm\\hmm\\hidden\\filters\\bayesian.py (63)\n\u001b[1m\nFile \"..\\..\\hidden\\filters\\bayesian.py\", line 63:\u001b[0m\n\u001b[1mdef forward_algo(\n    <source elided>\n\n\u001b[1m    for i, obs in enumerate(observations):\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of assignment at c:\\code\\hmm\\hmm\\hidden\\filters\\bayesian.py (63)\u001b[0m\n\u001b[1m\nFile \"..\\..\\hidden\\filters\\bayesian.py\", line 63:\u001b[0m\n\u001b[1mdef forward_algo(\n    <source elided>\n\n\u001b[1m    for i, obs in enumerate(observations):\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ANd then if you wanted a symmetric model\n",
    "A_init_sym = np.array([\n",
    "    [0.75, 0.25],\n",
    "    [0.25, 0.75]\n",
    "])\n",
    "\n",
    "B_init_sym = np.array([\n",
    "    [0.90, 0.10],\n",
    "    [0.10, 0.90]\n",
    "])\n",
    "\n",
    "result_local_sym = analyzer.optimize(obs_ts, A_init_sym, B_init_sym, symmetric=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Iterable, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', palette=\"hls\")\n",
    "\n",
    "# Import HMM libraries\n",
    "from hidden import dynamics\n",
    "from hidden import infer\n",
    "\n",
    "# here we assume the dynamics are symmetric\n",
    "a = 0.3\n",
    "b = 0.1\n",
    "A = np.array([[1 - a, a], [a, 1 - a]]) # eta symmetric matrix and parameter ekta \n",
    "B = np.array([[1 - b, b], [b, 1 - b]])\n",
    "\n",
    "hmm = dynamics.HMM(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Dynamics and Observation matrices\n",
    "hmm.initialize_dynamics(A, B)\n",
    "\n",
    "# Now run the dynamics for 1000 steps\n",
    "hmm.run_dynamics(1000)\n",
    "# And pull off the state and observation data\n",
    "state_ts = hmm.get_state_ts()\n",
    "\n",
    "import pandas as pd\n",
    "obs_ts=pd.read_csv(\"C:/Users/arumana/OneDrive - Viewpoint Capital Corporation/Documents/sample_1_2d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the likelihood here, using the bayesian predictions\n",
    "def calc_likelihood(\n",
    "    B: np.ndarray,\n",
    "    bayes_pred: Iterable[np.ndarray],\n",
    "    obs_ts: Iterable[int]\n",
    ") -> float:\n",
    "    likelihood = 0\n",
    "    for bayes, obs in zip(bayes_pred, obs_ts):\n",
    "        inner =  bayes @ B[:, obs]\n",
    "        likelihood -= np.log(inner)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward_algo() got an unexpected keyword argument 'prediction_tracker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m A_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a_test, a_test], [a_test, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a_test]])\n\u001b[0;32m      8\u001b[0m \u001b[39m# We can then generate the Bayesian filter for these dynamics\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m est\u001b[39m.\u001b[39;49mforward_algo(obs_ts, A_sample, B, prediction_tracker\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: forward_algo() got an unexpected keyword argument 'prediction_tracker'"
     ]
    }
   ],
   "source": [
    "# Now, we need a way of generating a Bayes estimate for a specific value of the transition parameter\n",
    "est = infer.MarkovInfer(2, 2)\n",
    "\n",
    "# For a stating point, lets assume that we try a = 0.4\n",
    "a_test = 0.4\n",
    "A_sample = np.array([[1 - a_test, a_test], [a_test, 1 - a_test]])\n",
    "\n",
    "# We can then generate the Bayesian filter for these dynamics\n",
    "est.forward_algo(obs_ts, A_sample, B, prediction_tracker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m ax\u001b[39m.\u001b[39maxhline(\u001b[39m0.5\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Calcalte the probability of begin in state 1 from the forward tracker\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m p1_fwd \u001b[39m=\u001b[39m [p[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m est\u001b[39m.\u001b[39mforward_tracker]\n\u001b[0;32m      5\u001b[0m ax\u001b[39m.\u001b[39mplot(p1_fwd[:\u001b[39m40\u001b[39m])\n\u001b[0;32m      6\u001b[0m ax\u001b[39m.\u001b[39mplot(state_ts[:\u001b[39m40\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39msns\u001b[39m.\u001b[39mxkcd_rgb[\u001b[39m\"\u001b[39m\u001b[39mshamrock\u001b[39m\u001b[39m\"\u001b[39m], markersize\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3.5))\n",
    "ax.axhline(0.5, color='k', linestyle='--')\n",
    "# Calcalte the probability of begin in state 1 from the forward tracker\n",
    "p1_fwd = [p[1] for p in est.forward_tracker]\n",
    "ax.plot(p1_fwd[:40])\n",
    "ax.plot(state_ts[:40], 'o', color=sns.xkcd_rgb[\"shamrock\"], markersize=7, alpha=0.6)\n",
    "ax.plot(obs_ts[:40], 'o',color=sns.xkcd_rgb[\"tangerine\"], markersize=4, alpha=0.6)\n",
    "\n",
    "ax.set_ylim([-0.05,1.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
