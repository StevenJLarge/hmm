{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "\n",
    "### Bayesian Filtering\n",
    "\n",
    "This notebook goes throught the Bayesian approach to analyzing and infering properties of hidden markov models (HMMs). Specifically, this notebook is the first in a series of developing implementations of several common analysis algorithms for HMMs, here focusing on the so-called *forward algorithm*, which we will refer to as Bayesian filtering.\n",
    "\n",
    "Intuitively, hidden markov models consist of an underlying *hidden* Markov process, which is uobservable to the outside world directly. As observers, we recieve measurements of this model--often known as emission symbols, or simply observations--which are plagued by noise, so that  \n",
    "\n",
    "In this notebook we will consider the simple case of a 2-dimensional HMM, in which we know the dynamics of the underlying Markov model (an assumption that we will remedy in a later notebook on system identification) as well as the observation/symbol-emission process. These two processes are codified by two matrices: $A$ and $B$.  The $A$ matrix has elements $A_{ij} \\equiv P(x_{t+1} = i | x_t = j)$ for states of the hidden system $x$, while the $B$ matrix has elements $B_{ij} \\equiv P(y_{t} = i | x_{t} = j)$ for the observed symbol $y_t$. Here, the $B$ matrix quantifies the probability of observing particualr symbols, given a particular state of the underlying state. In situations of a noiseless HMM (which would be the same as a Markov model), the $B$ matrix is simply an identity matrix.\n",
    "\n",
    "In any case, both $A$ and $B$ are known as *stochastic matrices*, and as a result their columns must sum to unity.\n",
    "\n",
    "For the same of completeness, we consider $x_t$ and $y_t$ to be the state of the underlying Markov model and observed symbol respectively, at time $t$. We also use the notation to indicate a sequence of states is writetn as $x_{[t,t-k]}$, while we indicate and entire history of states of $x$ (or $y$) as $x^T$.  \n",
    "\n",
    "We have developed, in a seaparate module in this local pacakage, a set of routines to generate dynamics of both the underlying Markovian system, as well as noisy observations of its dynamics. We will make use of this simulated dynamics to develop an estimation procedure for inferring the hidden state from past observed dynamics.  Specifically, we are interested in calculating\n",
    "\n",
    "$$ P(x_k | y^k) $$\n",
    "\n",
    "the conditional probability that the hidden state of the system is $x$ at time $k$, given the entire history of $k$ previous observations. In doing so we will be able to produce this conditional probability for all times, creating a history of our probabilistic belief on what the system state is.  This estimate also takes into account (at least formally) all available historical information to produce the estimate. This probability will effectively filter the observed process, and thus will be called the Bayesian filter of the observed dynamics.\n",
    "\n",
    "Mathematically, we can calculate the Bayesian probability by recursively updating our estimimate in a two-step update sequence:\n",
    "\n",
    "$$ P(x_{k+1}|y^k) = \\sum_{x_k}P(x_{k+1}|x_k)P(x_k | y^k) \\qquad \\text{(Prediction)} $$\n",
    "$$ P(x_{k+1}| y^{k+1}) = \\frac{1}{Z_{k+1}}P(y_{k+1} | x_{k+1})P(x_{k+1}| y^k) \\qquad \\text{(Update)} $$\n",
    "\n",
    "where $Z_{k+1}$ is a *partition function* defined as\n",
    "\n",
    "$$ Z_{k+1} \\equiv P(y_{k+1}| y^k) = \\sum_{x_{k+1}}P(y_{k+1} | x_{k+1})P(x_{k+1} | y^k) $$\n",
    "\n",
    "Thus, given an initial prior on $P(x_0|y_0)$, we can implement both of these steps in sequence with each new observation to build up a historical record of this conditional probability.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use(\"fivethirtyeight\")\n",
    "\n",
    "from hidden import dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the A and B matrices\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "\n",
    "A = np.array([[a, 1 - a], [1 - a, a]])\n",
    "B = np.array([[b, 1 - b], [1 - b, b]])\n",
    "\n",
    "# Now, initialize the dynamics\n",
    "hmm = dynamics.HMM(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.\n",
    "\n",
    "hmm.run_dynamics(100)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f9b37dac17d06b8fa0c89267880b723d82f0595bc5fc55c9df0f440e0daf16f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('hmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
