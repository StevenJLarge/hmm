{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New infrastructure for HMM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8, 0.2],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.9, 0.1],\n",
       "        [0.1, 0.9]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from hidden import dynamics, infer\n",
    "# This is only if you want to use non-default optimization routines (global)\n",
    "from hidden.optimize.base import OptClass\n",
    "\n",
    "# Initializedynamics\n",
    "hmm = dynamics.HMM(2, 2)\n",
    "hmm.init_uniform_cycle(0.2, 0.1)\n",
    "hmm.A, hmm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dynamics for 250 teps\n",
    "hmm.run_dynamics(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get observations\n",
    "obs_ts = hmm.get_obs_ts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize infer object\n",
    "analyzer = infer.MarkovInfer(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use initial 'guesses' for A and B to pass into the optimizer\n",
    "A_init = np.array([\n",
    "    [0.75, 0.3],\n",
    "    [0.25, 0.7]\n",
    "])\n",
    "\n",
    "B_init = np.array([\n",
    "    [0.95, 0.10],\n",
    "    [0.05, 0.90]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to run the optimization, we can call like this (these are all using\n",
    "# default arguments, so you dont actually need to include the symmetric or\n",
    "# opt_type arguments here)\n",
    "result_local = analyzer.optimize(obs_ts, A_init, B_init, symmetric=False, opt_type=OptClass.Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a global optimization (using SHGO algorithm)\n",
    "result_global = analyzer.optimize(obs_ts, A_init, B_init, symmetric=False, opt_type=OptClass.Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANd then if you wanted a symmetric model\n",
    "A_init_sym = np.array([\n",
    "    [0.75, 0.25],\n",
    "    [0.25, 0.75]\n",
    "])\n",
    "\n",
    "B_init_sym = np.array([\n",
    "    [0.90, 0.10],\n",
    "    [0.10, 0.90]\n",
    "])\n",
    "\n",
    "result_local_sym = analyzer.optimize(obs_ts, A_init_sym, B_init_sym, symmetric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hidden.optimize.results.LikelihoodOptimizationResult at 0x2b1a19a6a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to look at the results,\n",
    "result_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'L-BFGS-B',\n",
       " '_results':   message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "   success: True\n",
       "    status: 0\n",
       "       fun: 144.54649358650715\n",
       "         x: [ 2.109e-01  1.346e-01  7.096e-02  1.011e-01]\n",
       "       nit: 9\n",
       "       jac: [-3.695e-05  8.100e-04  1.990e-04  1.597e-03]\n",
       "      nfev: 65\n",
       "      njev: 13\n",
       "  hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>,\n",
       " '_report': None,\n",
       " 'likelihood': 144.54649358650715,\n",
       " '_optimal_params': array([0.2109368 , 0.1345636 , 0.07095823, 0.10110292]),\n",
       " 'A': array([[0.8654364, 0.2109368],\n",
       "        [0.1345636, 0.7890632]]),\n",
       " 'B': array([[0.89889708, 0.07095823],\n",
       "        [0.10110292, 0.92904177]]),\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the attributes on the result we can use the '__dict__' call:\n",
    "result_local.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8654364, 0.2109368],\n",
       "        [0.1345636, 0.7890632]]),\n",
       " array([[0.89889708, 0.07095823],\n",
       "        [0.10110292, 0.92904177]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The things we are most likely interested in are the A and B matrices, as\n",
    "# well as the optimal params (which will be in the A and B matrices)\n",
    "\n",
    "result_local.A, result_local.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8, 0.2],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.9, 0.1],\n",
       "        [0.1, 0.9]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are reasonably close to the inputs (for our number of time steps)\n",
    "hmm.A, hmm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'sobol',\n",
       " '_results':  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "      fun: 144.54649358467333\n",
       "     funl: [ 1.445e+02  1.445e+02  1.707e+02]\n",
       "        x: [ 2.109e-01  1.346e-01  7.096e-02  1.011e-01]\n",
       "       xl: [[ 2.109e-01  1.346e-01  7.096e-02  1.011e-01]\n",
       "            [ 1.346e-01  2.109e-01  8.989e-01  9.290e-01]\n",
       "            [ 9.990e-01  1.557e-01  5.809e-01  4.294e-01]]\n",
       "      nit: 2\n",
       "     nfev: 514\n",
       "    nlfev: 386\n",
       "    nljev: 71\n",
       "    nlhev: 0,\n",
       " '_report': None,\n",
       " 'likelihood': 144.54649358467333,\n",
       " '_optimal_params': array([0.21093731, 0.13456383, 0.07095807, 0.10110055]),\n",
       " 'A': array([[0.86543617, 0.21093731],\n",
       "        [0.13456383, 0.78906269]]),\n",
       " 'B': array([[0.89889945, 0.07095807],\n",
       "        [0.10110055, 0.92904193]]),\n",
       " 'metadata': {'local_min': array([[0.21093731, 0.13456383, 0.07095807, 0.10110055],\n",
       "         [0.1345638 , 0.21093728, 0.89889944, 0.92904193],\n",
       "         [0.999     , 0.15571613, 0.58085758, 0.42937842]])}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the global optimizer, we have some more stuff in the optimization result\n",
    "result_global.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.87019919, 0.10716253],\n",
       "        [0.12980081, 0.89283747]]),\n",
       " array([[0.91161992, 0.18385743],\n",
       "        [0.08838008, 0.81614257]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notable, the metatada['local_min'] which gives the local mimumum parameter values\n",
    "# but we still are probably most interested in the A and B arrays\n",
    "\n",
    "result_global.A, result_global.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'L-BFGS-B',\n",
       " '_results':   message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "   success: True\n",
       "    status: 0\n",
       "       fun: 148.87979720995418\n",
       "         x: [ 1.066e-01  1.490e-01]\n",
       "       nit: 10\n",
       "       jac: [-8.527e-06 -4.547e-05]\n",
       "      nfev: 48\n",
       "      njev: 16\n",
       "  hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>,\n",
       " '_report': None,\n",
       " 'likelihood': 148.87979720995418,\n",
       " '_optimal_params': array([0.10663528, 0.14901276]),\n",
       " 'A': array([[0.89336472, 0.10663528],\n",
       "        [0.10663528, 0.89336472]]),\n",
       " 'B': array([[0.85098724, 0.14901276],\n",
       "        [0.14901276, 0.85098724]]),\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, the symmetric model will look very similar but only have 2 parameters\n",
    "result_local_sym.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.89336472, 0.10663528],\n",
       "        [0.10663528, 0.89336472]]),\n",
       " array([[0.85098724, 0.14901276],\n",
       "        [0.14901276, 0.85098724]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_local_sym.A, result_local_sym.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
