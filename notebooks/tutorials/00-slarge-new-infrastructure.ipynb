{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New infrastructure for HMM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8, 0.2],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.9, 0.1],\n",
       "        [0.1, 0.9]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from hidden import dynamics, infer\n",
    "# This is only if you want to use non-default optimization routines (global)\n",
    "from hidden.optimize.base import OptClass\n",
    "\n",
    "# Initializedynamics\n",
    "hmm = dynamics.HMM(2, 2)\n",
    "hmm.init_uniform_cycle(0.2, 0.1)\n",
    "hmm.A, hmm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dynamics for 250 teps\n",
    "hmm.run_dynamics(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get observations\n",
    "obs_ts = hmm.get_obs_ts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize infer object\n",
    "analyzer = infer.MarkovInfer(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use initial 'guesses' for A and B to pass into the optimizer\n",
    "A_init = np.array([\n",
    "    [0.75, 0.3],\n",
    "    [0.25, 0.7]\n",
    "])\n",
    "\n",
    "B_init = np.array([\n",
    "    [0.95, 0.10],\n",
    "    [0.05, 0.90]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to run the optimization, we can call like this (these are all using\n",
    "# default arguments, so you dont actually need to include the symmetric or\n",
    "# opt_type arguments here)\n",
    "result_local = analyzer.optimize(obs_ts, A_init, B_init, symmetric=False, opt_type=OptClass.Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a global optimization (using SHGO algorithm)\n",
    "result_global = analyzer.optimize(obs_ts, A_init, B_init, symmetric=False, opt_type=OptClass.Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANd then if you wanted a symmetric model\n",
    "A_init_sym = np.array([\n",
    "    [0.75, 0.25],\n",
    "    [0.25, 0.75]\n",
    "])\n",
    "\n",
    "B_init_sym = np.array([\n",
    "    [0.90, 0.10],\n",
    "    [0.10, 0.90]\n",
    "])\n",
    "\n",
    "result_local_sym = analyzer.optimize(obs_ts, A_init_sym, B_init_sym, symmetric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hidden.optimize.results.LikelihoodOptimizationResult at 0x2745cee5bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to look at the results,\n",
    "result_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'L-BFGS-B',\n",
       " '_results':   message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "   success: True\n",
       "    status: 0\n",
       "       fun: 148.3308219706871\n",
       "         x: [ 1.072e-01  1.298e-01  1.839e-01  8.838e-02]\n",
       "       nit: 11\n",
       "       jac: [ 3.297e-04  2.160e-04  3.496e-04  2.899e-04]\n",
       "      nfev: 75\n",
       "      njev: 15\n",
       "  hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>,\n",
       " '_report': None,\n",
       " 'likelihood': 148.3308219706871,\n",
       " '_optimal_params': array([0.10716288, 0.12980124, 0.18385793, 0.08838036]),\n",
       " 'A': array([[0.87019876, 0.10716288],\n",
       "        [0.12980124, 0.89283712]]),\n",
       " 'B': array([[0.91161964, 0.18385793],\n",
       "        [0.08838036, 0.81614207]]),\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the attributes on the result we can use the '__dict__' call:\n",
    "result_local.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.87019876, 0.10716288],\n",
       "        [0.12980124, 0.89283712]]),\n",
       " array([[0.91161964, 0.18385793],\n",
       "        [0.08838036, 0.81614207]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The things we are most likely interested in are the A and B matrices, as\n",
    "# well as the optimal params (which will be in the A and B matrices)\n",
    "\n",
    "result_local.A, result_local.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8, 0.2],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.9, 0.1],\n",
       "        [0.1, 0.9]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are reasonably close to the inputs (for our number of time steps)\n",
    "hmm.A, hmm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'sobol',\n",
       " '_results':  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "      fun: 148.33082197045823\n",
       "     funl: [ 1.483e+02  1.483e+02]\n",
       "        x: [ 1.072e-01  1.298e-01  1.839e-01  8.838e-02]\n",
       "       xl: [[ 1.072e-01  1.298e-01  1.839e-01  8.838e-02]\n",
       "            [ 1.298e-01  1.072e-01  9.116e-01  8.161e-01]]\n",
       "      nit: 2\n",
       "     nfev: 312\n",
       "    nlfev: 184\n",
       "    nljev: 33\n",
       "    nlhev: 0,\n",
       " '_report': None,\n",
       " 'likelihood': 148.33082197045823,\n",
       " '_optimal_params': array([0.10716253, 0.12980081, 0.18385743, 0.08838008]),\n",
       " 'A': array([[0.87019919, 0.10716253],\n",
       "        [0.12980081, 0.89283747]]),\n",
       " 'B': array([[0.91161992, 0.18385743],\n",
       "        [0.08838008, 0.81614257]]),\n",
       " 'metadata': {'local_min': array([[0.10716253, 0.12980081, 0.18385743, 0.08838008],\n",
       "         [0.12980081, 0.10716251, 0.9116199 , 0.81614255]])}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the global optimizer, we have some more stuff in the optimization result\n",
    "result_global.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.87019919, 0.10716253],\n",
       "        [0.12980081, 0.89283747]]),\n",
       " array([[0.91161992, 0.18385743],\n",
       "        [0.08838008, 0.81614257]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notable, the metatada['local_min'] which gives the local mimumum parameter values\n",
    "# but we still are probably most interested in the A and B arrays\n",
    "\n",
    "result_global.A, result_global.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " '_algo_name': 'L-BFGS-B',\n",
       " '_results':   message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "   success: True\n",
       "    status: 0\n",
       "       fun: 148.87979720995418\n",
       "         x: [ 1.066e-01  1.490e-01]\n",
       "       nit: 10\n",
       "       jac: [-8.527e-06 -4.547e-05]\n",
       "      nfev: 48\n",
       "      njev: 16\n",
       "  hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>,\n",
       " '_report': None,\n",
       " 'likelihood': 148.87979720995418,\n",
       " '_optimal_params': array([0.10663528, 0.14901276]),\n",
       " 'A': array([[0.89336472, 0.10663528],\n",
       "        [0.10663528, 0.89336472]]),\n",
       " 'B': array([[0.85098724, 0.14901276],\n",
       "        [0.14901276, 0.85098724]]),\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, the symmetric model will look very similar but only have 2 parameters\n",
    "result_local_sym.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.89336472, 0.10663528],\n",
       "        [0.10663528, 0.89336472]]),\n",
       " array([[0.85098724, 0.14901276],\n",
       "        [0.14901276, 0.85098724]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_local_sym.A, result_local_sym.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
